## What is Azure Data Factory (ADF)?
A cloud-based data integration service that orchestrates data movement and transformation between diverse data sources and cloud compute resources at scale.

## Top-level concepts
ADF is composed of below key components:

* [Pipelines](#Pipelines)
* [Activities](#Activities)
* [Datasets](#Datasets)
* [Linked services](#Linkedservices)
* [Data Flows](#DataFlows)
* [Integration Runtimes](#IntegrationRuntimes)

<div id="Pipelines"></div>
## Pipelines

A pipeline is a logical grouping of activities that performs a unit of work.

<div id="Activities"></div>
## Activities

Activities represent a processing step in a pipeline. Data Factory supports three types of activities: data movement activities, data transformation activities, and control activities.

<div id="Datasets"></div>
## Datasets

Datasets represent data structures within the data stores, which simply point to or reference the data you want to use in your activities as inputs or outputs.

<div id="Linkedservices"></div>
## Linked services

Linked services are much like connection strings, which define the connection information that's needed for Data Factory to connect to external resources.

<div id="DataFlows"></div>
## Data Flows

Create and manage graphs of data transformation logic that you can use to transform any-sized data.

<div id="IntegrationRuntimes"></div>
## Integration Runtimes

An integration runtime provides the bridge between the activity and linked Services. It's referenced by the linked service or activity and provides the compute environment where the activity either runs on or gets dispatched from.

## Get started with Azure Data Factory
Login URL: portal.azure.com  
User name â€“ your email id  
Password - your password  


